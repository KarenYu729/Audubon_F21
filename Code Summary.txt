

configs --------------------------------------------------------------
4 Files containing hyperparameter values

scripts --------------------------------------------------------------

data_exploration.py

    draw_bounding_boxes(img, data, legend=True): 
        """
        Function to draw bounding boxes onto image 
        INPUTS: 
            img -- <numpy.ndarray> input image for bounding boxes to be placed on
            data -- <pandas.DataFrame> dataframe containing columns for object class and 
                    bounding box parameters (x, y, width, height)
            legend -- <boolean> toggle to place legend on plot 
        OUTPUTS: 
            output -- <numpy.ndarray> edited input image with bounding boxes
        """
    # Doesn't actually output anything, just plots the image with the bounding boxes overlaid

    dataLoader():
        """
        Function to load data in for data exploration
        INPUTS: 
            
        OUTPUTS: 
            target_data -- <pd.dataframe> dataframe with bounding boxes processed and aggregated
        """
    # As it doesn't have arguments, it's specific to a directory containing annotation CSV files - can edit this

    birdCounts(target_data):
        """
        Function to display bird counts graphic
        INPUTS: 
            target_data -- <pd.dataframe> dataframe with bounding boxes processed and aggregated
        OUTPUTS: 
        """
    # Think this plots the horizontal bar plot for the dataframe passed

    birdPerPhoto(target_data):
        """
        Function to display bird per photo graphic
        INPUTS: 
            target_data -- <pd.dataframe> dataframe with bounding boxes processed and aggregated
        OUTPUTS: 
        """
    # Plots the pie plot which shows how many images had, for example, 21-40 birds, etc

    birdExamples():
        """
        Function to display examples of each bird
        INPUTS: 
        OUTPUTS: 
        """
    # As it doesn't have arguments, it's specific to a directory containing annotation CSV files - can edit this

    # TODO: Lastly, file contains this at the bottom, which means...
    if __name__ == 'main':
        target_data = dataLoader()
        birdCounts(target_data)
        birdPerPhoto(target_data)
        birdExamples()

utils ----------------------------------------------------------------

config.py

    add_retinanet_config(args):
        # For retinanet model
        # Createss detectron2 config and predictor and sets parameter settings (loss, solver, etc)
        # Can load pretrained weights from file
        # Returns cfg object

    add_fasterrcnn_config(args):
        # For fasterrcnn model
        # Createss detectron2 config and predictor and sets parameter settings (loss, solver, etc)
        # Can load pretrained weights from file
        # Returns cfg object

dataloader.py

    get_bird_only_dicts(data_dir,img_ext='.JPG'):
        """
        Format dataset to detectron2 standard format. 
        INPUTS: 
            data_dir -- directory containing dataset files 
            img_ext -- file extension for images in dataset
        OUTPUTS: 
            dataset_dicts -- list of dictionaries in detectron2 standard format
        """
    # dataset_dicts is a list of dictionaries, one for each image. Each dictionary has one key,
    #   "annotations", whose value is a list of dictionaries, one for each bird in the image

    get_bird_species_dicts(data_dir,class_names,img_ext='.JPG',unknown_bird_category=True,skip_empty_imgs=True):
        """
        Format dataset to detectron2 standard format. 
        INPUTS: 
            data_dir -- directory containing dataset files 
            img_ext -- file extension for images in dataset
            class_names -- names of bird species
            unknown_bird_categories  -- store dicts for birds belonging to 'Unknown' class
            skip_empty_imgs -- skip images with no birds 
        OUTPUTS: 
            dataset_dicts -- list of dictionaries in detectron2 standard format
        """
    # Essentially the same function as above, except that the dictionaries containing all birds in
    #   each image have been split into smaller dictionaries by species

    def register_datasets(data_dirs, img_ext, birds_species_names, bird_species_colors=None):
        """
        Register dataset as part of Detectron2's dataset and metadataset catalogs
        For each dataset directory to be registered, a "bird-only" and "bird-species" dataset will be registered
        INPUTS:
            data_dirs: list of directories containing dataset images to be registered
            img_ext: file extension for images in dataset
            birds_species_names: List of names of bird species to be registered. Species not in this list will be registered as
                                "Unknown Bird"
            bird_species_colors: List of colors for corresponding to bird species to be used for visualizations. Color
                                format should be tuple containing RGB values between 0-255 eg. (255,0,0) for red

        """
    # For the "bird-only" registration, all birds are labeled as just "Bird", while "bird-species"
    #   has the species labels (passed as argument), along with "Unknown"

plotting.py

    def plot_img_bbx(image, annotation_lst, color_dict=None):
        """
        This is a plotting function to check if the bndbox annotations convertion is done correctly
        INPUT:
        image -- PIL image module to be
        annotation_lst -- a list containing all the annotations for this image
        color_dict -- a dictionary containing color scheme to be used to outline bounding boxes for each class
        """
    # Edited or created for use on AWS

cropping.py

    csv_to_dict_AWS(bucket_name, key,  im_fold, AWS_storage = 's3',annot_file_ext='bbx'):
        """
        Function to extract an info dictionary from an xml file
        INPUT:
        csv_path -- path for an csv file, format of bndbox should be xmin, ymin,
                    xmax, ymax
        OUTPUT:
        info_dict -- an info dictionary ######## (format is class, desc, xmin, ymin, xmax, ymax)
        """
    # info_dict is a dictionary of dictionaries, one for each bird
    # it has two keys: 'bbx', whose value is the list of dictionaries;
    #   and 'file', whose value is the image file name

    csv_to_dict(csv_path, class_map = {}, test=False, annot_file_ext='csv'):
        """
        Function to extract an info dictionary from an xml file
        INPUT:
            csv_path -- path for an csv file, format of bndbox should be xmin, ymin,
                        xmax, ymax
        OUTPUT:
            info_dict -- an info dictionary ######## (format is class, desc, xmin, ymin, xmax, ymax)
        """
    # original function, does the same as above

    dict_to_csv(info_dict, output_path, empty):
        """
        Function to convert (cropped images') info_dicts to annoatation csv files
        INPUT:
        info_dict -- output from the csv_to_dict function, containing bbox, filename, img_size
        output_path -- folder path to store the converted csv files
        OUTPUT:
        an csv file(corresponding for 1 image) saved to a folder. The bndbox info in the format of (className,
        xmin, ymin, width, height)
        """
    # info_dict has the format (class, desc, xmin, ymin, xmax, ymax) but the csv format is
    #   (class, desc, xmin, ymin, width, height) as before

    tile_annot(left, right, top, bottom, info_dict, i, j, crop_height, crop_width, overlap, file_dict):
        """
        THIS FUNCTION calculate the new positions of bndbox in cropped img and append them to file_dict,
        which is an info dict for that cropped img.

        INPUTS:
        left, right, top, bottom -- params for the python crop img function, coordinates for tiles.
        origin is top left.
        info_dict -- the info_dict we get from the csv_to_dict function.
        overlap -- threshold for keeping a bbox.
        """
    # This function finds the xmin, ymin, xmax, ymax of a bounding box with respect to the cropped image
    # file_dict is passed as an argument and updated. valid (boolean) is returned, corresponding to at
    #   least one bird being in the cropped image
    # file_dict is a list of dictionaries, where each entry corresponds to a cropped image. Each dictionary
    #   has key "bbox", whose value that is a list of dictionaries, one per bird in the cropped image
    # I think top, left, right, bottom are the pixels of the original images containing the cropped image
    # Should line 152, the statement after the OR, be surrounded by parentheses?
    # Lines 159-162 can use xmin, xmax, ymin, ymax since they were calculated above?
    # str(i) + '_' + str(j) can be replaced by a properly named variable

    crop_img(csv_file, crop_height, crop_width, output_dir, class_map = {}, overlap=0.2, annot_file_ext='csv', file_dict={}):
        """
        This function crops one image and output corresponding labels.
        Currently, this function generates the cropped images AND the corresponding csv files to output_dir
        INPUT:
        crop_height, crop_weight -- desired patch size.
        overlap -- threshold for keeping bbx.
        annot_file_ext -- annotation file extension
        """
    # this function generates all the cropped images and all corresponding label txt files for a single file
    # file_dict stores cropped images info dict in one dictionary.
    # Uses tile_annot. Looks like cropped images without birds are not saved (line 214)
    # overlap is defaulted to 0.2
    # Looks like images are saved to two different directories - the Intermediate one is then deleted
    #   in crop_dataset()
    # Don't need empty = True on line 225
    # Each file_dict entry is saved to a csv file, hence there is a csv file for each cropped image
    #   which contains the new bounding box info for each bird in the cropped image

    crop_dataset(data_dir, output_dir, annot_file_ext = 'csv', class_map = {}, crop_height=640, crop_width=640):
        """
        :param data_dir: image set directory
        :param output_dir: output directory
        :param annot_file_ext: annotation file extension
        :param crop_height: image height after tiling, default 640
        :param crop_width: image width after tiling, default 640
        """
    # This function applies crop_img to each csv file in data_dir
    # output_dir then contains the cropped images and their corresponding csv files
    # The Intermediate directory is deleted here

    crop_img_only(img_file_path, output_path, crop_height, crop_width, sliding_size):
        """
        This function crops one image with an adjustable overlap
        INPUT:
        crop_height, crop_weight -- desired patch size.
        """
    # Crops individual image passed with varibale sliding size that allows for overlap
    # This function and the next function are very similar to the two above but they don't save the
    #   bird info into dictionaries. They just save crop and save the images and are used in prediction
    #   stage of the pipeline

    crop_dataset_img_only(data_dir, img_ext, output_dir, crop_height=640, crop_width=640, sliding_size=400):
        """
        This function crops image dataset with adjustable sliding size. Bounding boxes are not cropped alongside images.
        Function is to be used during final pipeline stage for prediction
        INPUTS:
            :param data_dir: image set directory
            :param img_ext: image file extension eg. ".JPG"
            :param output_dir: output directory
            :param crop_height: image height after tiling, default 640
            :param crop_width: image width after tiling, default 640
            :param sliding_size: sliding size between each crop, default 400
        """
    # Applies crop_img_only to each csv file in data_dir (the Intermediate directory is deleted here too)
    # output_dir then contains the cropped images
    # Doesn't check if the output directory exists first, while crop_dataset() does 
    
    train_val_test_split(file_dir, output_dir, train_frac=0.8, val_frac=0.1):
        """
        :param file_dir: crop_dataset()'s output path:
        :param output_dir: an empty folder
        :param train_frac: fraction for training
        :param val_frac: fraction for validation, 1-train-val will be fraction for test
        """
    # Shuffles the images contained in file_dir and moves them into train, val and test subdirectories
    # Their csv files are also moved move them (they need to be file_dir)
    # Uses a seed of 4 for Random
    # output_dir and its three subdirectories (train, val, test) need to be created beforehand

trainer.py

    class WAndBWriter(EventWriter):
        Not really sure what this is
    
    class ValidationLossHook(HookBase):
        __init__(self, model, data_loader, eval_period=20):
        _do_loss_eval(self): 
        _get_loss(self, data):
        after_step(self):
    # Class for evaluating the loss of the model as it is trained
    # Loss is reported is the mean of the batch size losses
    
    class Trainer(DefaultTrainer):
        build_evaluator(cls, cfg, dataset_name, output_folder=None):
        build_hooks(self):

    class WAndBTrainer(DefaultTrainer):
        build_evaluator(cls, cfg, dataset_name, output_folder=None):
        build_hooks(self):

    build_writers(self):
    # Code is:
        writers = super().build_writers()
        writers.append(WAndBWriter())
        return writers

evaluation.py
    
    class PrecisionRecallEvaluator(COCOEvaluator):
        """
        Evaluate all Precision-Recall metrics for instance detection obtained from detectron2 COCOEvalulator
        """

        __init__(self,dataset_name,output_dir=None):

        evaluate(self, img_ids=None):
            """
            Args:
                img_ids: a list of image IDs to evaluate on. Default to None for the whole dataset
            Outputs: (see COCOEval API for details)
                precisions  - [TxRxKxAxM] precision for every evaluation setting
                recalls    - [TxKxAxM] max recall for every evaluation setting

            """

        _coco_eval_predictions(self, predictions, img_ids=None):

    get_precisions_recalls(cfg, predictor, dataset_name):
        """
        get precisions and recalls outputted by PrecisionRecallEvaluator
        INPUTS:
            cfg -- detectron2 CfgNode
            predictor -- detectron2 predictor
            dataset_name -- registered dataset name to evaluate on
        """
        # Code is:
            evaluator = PrecisionRecallEvaluator(dataset_name, output_dir=cfg.OUTPUT_DIR)
            data_loader = build_detection_test_loader(cfg, dataset_name)
            return inference_on_dataset(predictor.model, data_loader, evaluator)

    plot_precision_recall(precisions, max_recalls, class_names, class_colors):
        """
        Plot precision-recall curves outputted by PrecisionRecallEvaluator
        INPUTS:
            precisions: [TxRxKxAxM] precision for every evaluation setting
            max_recalls: [TxKxAxM] max recall for every evaluation setting
            class_names: names of bird species registered.
            class_colors: List of colors for corresponding to bird species
        """
    # Plots avg precision vs max_recall (meaning?), Precision-Recall Curve (IoU = 0.5), and Precision-Recall Curve (IoU = 0.75)
    # Bug in line 148, test_precisions not defined

    non_max_suppression_fast(df, overlap_thresh = 0.5):
        """
        Perform non-maximal supression for bounding boxes
        Adapted from https://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/
        INPUTS
            df -- pandas dataframe containing bounding boxes
            overlapThresh -- overlapping IoU threshold to be used for rejection (default: 0.5)
        OUTPUT
            df -- pandas dataframe containing bounding boxes after NMS
        """
    # Removes entries from df if their bounding boxes overlap by more than the threshold
    # Bug: Looks like all are returned because pick appends all the indices
    # Can't see how does calculates IoU ratio and how it removes redundant bounding boxes while
    #   keeping one

    evaluate_full_pipeline(eval_file_lst, predictor, species_map, raw_img_width, raw_img_height,
                           crop_width, crop_height, sliding_size):
        obj_dict = {'cnt_id': [], 'file_name': [], 'xmin': [], 'ymin': [], 'xmax': [], 'ymax': [],
            'score': [], 'pred_cls': []}
        for f in tqdm(eval_file_lst):
            # stuff
            output_df = pd.DataFrame(obj_dict)
            # Four functions are created, then applied
    # Doesn't look correctly written. obj_dict becomes a DataFrame in the first iteration, yet
    #   it's converted at every loop. The four functions are also defined at every loop
    # output_df is returned, which has had overlapping boundary boxes removed

    class ConfusionMatrix(object):
        __init__(self, num_classes: int, labels: list):
        update(self, preds, labels):
        summary(self):
        plot(self):
    # Added by us (Spring 22)